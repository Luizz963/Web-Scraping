# WebScrapping
Projeto de WebScrapping utilizando o site AdoroCinema

# ğŸ¬ Web Scraping - CrÃ­ticas de Filmes (AdoroCinema)

Este projeto realiza **web scraping** no site [AdoroCinema](https://www.adorocinema.com/filmes/criticas-filmes/) para extrair informaÃ§Ãµes detalhadas de filmes recentemente avaliados, e organiza esses dados em uma estrutura de **DataFrame** com o auxÃ­lio da biblioteca `pandas`.

---

## ğŸ¯ Objetivo

Extrair de forma automatizada informaÃ§Ãµes importantes de filmes diretamente do site AdoroCinema, incluindo:

- ğŸ¬ TÃ­tulo  
- ğŸ¥ DireÃ§Ã£o  
- ğŸ‘¥ Elenco  
- ğŸ—“ï¸ Data de lanÃ§amento  
- ğŸ“º Meio de lanÃ§amento (cinema, streaming etc.)  
- â­ Nota da crÃ­tica (redaÃ§Ã£o do site)

Esses dados sÃ£o organizados em um `DataFrame` para futura anÃ¡lise, exportaÃ§Ã£o ou visualizaÃ§Ã£o.

---

## âš™ï¸ Como o CÃ³digo Funciona

1. **RequisiÃ§Ã£o HTTP**: Usa `requests` para acessar a pÃ¡gina principal de crÃ­ticas de filmes.
2. **Parsing HTML**: Com `BeautifulSoup`, localiza os blocos de HTML contendo os filmes.
3. **ExtraÃ§Ã£o de links individuais**: Para cada filme listado, acessa a pÃ¡gina detalhada.
4. **Coleta de dados**: Extrai dados como direÃ§Ã£o, elenco, data de estreia, meio de lanÃ§amento e nota.
5. **Armazenamento**: Os dados sÃ£o guardados em uma lista de dicionÃ¡rios (`lista_filmes`).
6. **CriaÃ§Ã£o de DataFrame**: Utiliza `pandas` para transformar os dados em um `DataFrame` organizado.
7. **ExibiÃ§Ã£o**: Mostra o conteÃºdo no terminal, pronto para ser exportado para `.csv`, `.json` ou processado.

---

## ğŸ§° Bibliotecas Utilizadas

- [`requests`](https://pypi.org/project/requests/): Para fazer requisiÃ§Ãµes HTTP.  
- [`BeautifulSoup`](https://pypi.org/project/beautifulsoup4/): Para fazer o parsing e navegaÃ§Ã£o no HTML.  
- [`pandas`](https://pandas.pydata.org/): Para criar e manipular tabelas (DataFrames) com os dados coletados.

---

## ğŸ“Œ Resultados Esperados

Ao rodar o script, o terminal exibirÃ¡:
- InformaÃ§Ãµes detalhadas de cada filme listado.
- Um `DataFrame` estruturado com todos os dados organizados.

---

## ğŸ“¦ PossÃ­veis ExpansÃµes

- Exportar os dados para um arquivo `.csv` ou `.json`.
- Criar uma interface interativa com grÃ¡ficos usando `streamlit` ou `dash`.
- Agendar a coleta automÃ¡tica com `cron` ou `task scheduler`.

---
